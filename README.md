# 6조 기계학습 프로젝트 - 매출 예측을 위한 군집 기반 분석

팀원 :

---

## 📌 프로젝트 개요

본 프로젝트는 서울 시내의 버스 및 지하철 역 좌표 데이터를 활용하여 군집화를 수행한 후,<br><br>
각 군집에 대해 매출을 예측하는 모델을 개발하는 데 목적이 있습니다.<br><br>
궁극적으로 자영업자들에게 유용한 매출 인사이트를 제공하는 웹 기반 서비스를 구현하고자 합니다.

---

## 📊 데이터 구성 및 전처리

- **초기 데이터**
  - 역 개수: 11,561개
  - 중복 제거 후 고유 역 수: 7,477개

- **전처리**
  - 중복된 역(예: 광화문역) 통합
  - 좌표 기반 시각화
  - 버스역 + 지하철역 통합 산점도 생성

![역 산점도](images/station_scatter_plot.png)  
> 그림 1. 서울 시내 7477개 역의 분포를 지도 위에 시각화한 결과

---

## 🔍 데이터 분석 및 군집화

- **군집화 대상:** 7,477개의 역
- **기법:** K-Means

- **K 값 탐색**
  - 엘보우 기법 기준: inertia가 완만해지는 지점 ≈ K=25 이상
  - 실루엣 계수 기준: 최대값 K=2550 → 과적합 우려

![군집화 시각화](images/kmeans_cluster_result.png)  
> 그림 2. K-Means로 군집화한 7477개의 역. 각 색상은 서로 다른 군집을 나타냄.

![엘보우 기법](images/elbow_method.png)  
> 그림 3. 엘보우 기법을 사용한 inertia 분석. K값이 약 25 이상부터 효과 감소.

![실루엣 계수](images/silhouette_score.png)  
> 그림 4. K값에 따른 실루엣 계수. 2550일 때 가장 높지만, 해석 가능성 낮음.

- **최적 K 값 결정**
  - 최종 군집 수: K=259
  - 이유: 많은 군집을 통합하면서도 유의미한 상관관계 확보

![K=259 군집화 결과](images/kmeans_259.png)  
> 그림 5. 최종 선정된 K=259일 때의 군집화 결과. 변수 간 상관관계 개선됨.

---

## 🏗️ 기준 테이블 구성

- 기준 테이블: 지하철/버스의 시간대별 승하차 데이터 (0시 ~ 23시)
- 2550개 군집 기반의 최종 통합 테이블
- 메인 데이터셋 구축

---

## 📉 예측 모델링

### 사용된 모델
- 선형 회귀 (Baseline)
- XGBoost
- LightGBM
- 랜덤 포레스트

### 성능 비교 (RMSLE)

| 모델 유형             | RMSLE        |
|----------------------|--------------|
| Baseline (선형 회귀) | 3.79266662887 |
| 프로젝트 모델         | 0.00899928144 |

![모델 성능 비교](images/rmsle_comparison.png)  
> 그림 6. RMSLE 성능 비교. 프로젝트 모델이 실제 상황에 더 적합한지 추가 해석 필요

---

## 🧰 기술 스택

- **프레임워크**: Scikit-Learn
- **라이브러리**: Numpy, Pandas
- **개발환경**: Google Colab

---

## 🎯 최종 목표

- 학습된 모델을 웹사이트 형태로 배포
- 매출과 높은 상관관계를 가지는 변수에 대한 인사이트 제공
- 자영업자들의 매출 향상에 도움을 주는 서비스 구축


