```py
# 필요한 라이브러리 임포트
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# --- 데이터 로드 및 준비 ---
# 사용자님의 코드에서 'data' 변수에 이미 CSV 파일이 로드되어 있다고 가정합니다.
# 예: data = pd.read_csv('/content/drive/MyDrive/찐막데이터.csv', encoding='cp949')
# 필요하다면 Unnamed: 0.1 컬럼 삭제 코드 추가
# if 'Unnamed: 0.1' in data.columns:
#     data = data.drop(columns=['Unnamed: 0.1'])

# 요청하신 컬럼 목록
all_listed_columns = [
    '당월_매출_금액', '당월_매출_건수', '주중_매출_금액', '주말_매출_금액',
    '월요일_매출_금액', '화요일_매출_금액', '수요일_매출_금액', '목요일_매출_금액', '금요일_매출_금액',
    '토요일_매출_금액', '일요일_매출_금액', '시간대_00~06_매출_금액', '시간대_06~11_매출_금액',
    '시간대_11~14_매출_금액', '시간대_14~17_매출_금액', '시간대_17~21_매출_금액',
    '시간대_21~24_매출_금액', '남성_매출_금액', '여성_매출_금액', '연령대_10_매출_금액',
    '연령대_20_매출_금액', '연령대_30_매출_금액', '연령대_40_매출_금액', '연령대_50_매출_금액',
    '연령대_60_이상_매출_금액', '주중_매출_건수', '주말_매출_건수', '월요일_매출_건수', '화요일_매출_건수',
    '수요일_매출_건수', '목요일_매출_건수', '금요일_매출_건수', '토요일_매출_건수', '일요일_매출_건수',
    '시간대_건수~06_매출_건수', '시간대_건수~11_매출_건수', '시간대_건수~14_매출_건수',
    '시간대_건수~17_매출_건수', '시간대_건수~21_매출_건수', '시간대_건수~24_매출_건수', '남성_매출_건수',
    '여성_매출_건수', '연령대_10_매출_건수', '연령대_20_매출_건수', '연령대_30_매출_건수',
    '연령대_40_매출_건수', '연령대_50_매출_건수', '연령대_60_이상_매출_건수'
]

# 데이터프레임에 요청된 모든 컬럼이 있는지 확인
missing_cols = [col for col in all_listed_columns if col not in data.columns]
if missing_cols:
    print(f"경고: 다음 컬럼들이 데이터프레임에 없습니다: {missing_cols}")
    # 없는 컬럼은 분석에서 제외하거나 데이터 로드 부분을 확인해야 합니다.
    # 여기서는 있는 컬럼만 사용하도록 all_listed_columns를 업데이트합니다.
    all_listed_columns = [col for col in all_listed_columns if col in data.columns]

# 종속 변수(y)와 독립 변수(X) 설정
target_column = all_listed_columns # 종속 변수 설정 (가정 1)

# 독립 변수는 나열된 컬럼 중 종속 변수 제외 (가정 2)
feature_columns = [col for col in all_listed_columns if col != target_column]

# 실제 사용할 데이터프레임 생성
data_subset = data[all_listed_columns]

# 결측치 제거 (독립 변수와 종속 변수 모두 고려)
if data_subset.isnull().any().any():
    print("선택된 컬럼에 결측값이 존재하여 해당 행을 제거합니다.")
    data_cleaned = data_subset.dropna().copy()
else:
    data_cleaned = data_subset.copy()

# 최종 X와 y 설정
X = data_cleaned[feature_columns]
y = data_cleaned[target_column]

print("독립 변수 (X) 데이터셋 크기:", X.shape)
print("종속 변수 (y) 데이터셋 크기:", y.shape)

# --- 데이터 분할 ---
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("\n학습 데이터셋 크기:", X_train.shape)
print("테스트 데이터셋 크기:", X_test.shape)

# --- 랜덤 포레스트 회귀 모델 학습 ---

# RandomForestRegressor 모델 초기화 및 학습
model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)

print("\n랜덤 포레스트 모델 학습 시작...")
model.fit(X_train, y_train)
print("모델 학습 완료.")

# --- 모델 평가 ---

# 테스트 데이터로 예측 수행
predictions = model.predict(X_test)

# 모델 성능 평가
mse = mean_squared_error(y_test, predictions)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, predictions)

print("\n--- 모델 평가 결과 ---")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"R-squared (R2) Score: {r2:.4f}")

# --- 피처 중요도 확인 (선택 사항) ---
print("\n--- 피처 중요도 (상위 10개) ---")
feature_importances = pd.Series(model.feature_importances_, index=X.columns)
feature_importances_sorted = feature_importances.sort_values(ascending=False)
print(feature_importances_sorted.head(10))

```
